{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training and testing datasets to our local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "urls = {\n",
    "        'X_train' : \"https://s3.amazonaws.com/drivendata/data/7/public/4910797b-ee55-40a7-8668-10efd5c1b960.csv\",\n",
    "        'y_train' : \"https://s3.amazonaws.com/drivendata/data/7/public/0bf8bc6e-30d0-4c50-956a-603fc693d966.csv\",\n",
    "        'X_test' : \"https://s3.amazonaws.com/drivendata/data/7/public/702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv\",\n",
    "        'y_test' : \"https://s3.amazonaws.com/drivendata/data/7/public/SubmissionFormat.csv\"\n",
    "        }\n",
    "\n",
    "for i in urls:\n",
    "    r = requests.get(urls[i])\n",
    "\n",
    "    text = r.iter_lines()\n",
    "\n",
    "    reader = csv.reader(text, delimiter=',')\n",
    "\n",
    "    mylist = list(reader)\n",
    "\n",
    "    with open(str(i)+'.csv', 'wb') as fp:\n",
    "        a = csv.writer(fp, delimiter=',')\n",
    "        data = mylist\n",
    "        a.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our train and test datasets into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect our target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del y_train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 0.543081\n",
       "non functional             0.384242\n",
       "functional needs repair    0.072677\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['status_group'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id , 0.0% nulls , <type 'numpy.int64'> 59400\n",
      "amount_tsh , 0.0% nulls , <type 'numpy.float64'> 98\n",
      "date_recorded , 0.0% nulls , <type 'str'> 356\n",
      "funder , 6.1% nulls , <type 'str'> 1897\n",
      "gps_height , 0.0% nulls , <type 'numpy.int64'> 2428\n",
      "installer , 6.2% nulls , <type 'str'> 2145\n",
      "longitude , 0.0% nulls , <type 'numpy.float64'> 57516\n",
      "latitude , 0.0% nulls , <type 'numpy.float64'> 57517\n",
      "wpt_name , 0.0% nulls , <type 'str'> 37400\n",
      "num_private , 0.0% nulls , <type 'numpy.int64'> 65\n",
      "basin , 0.0% nulls , <type 'str'> 9\n",
      "subvillage , 0.6% nulls , <type 'str'> 19287\n",
      "region , 0.0% nulls , <type 'str'> 21\n",
      "region_code , 0.0% nulls , <type 'numpy.int64'> 27\n",
      "district_code , 0.0% nulls , <type 'numpy.int64'> 20\n",
      "lga , 0.0% nulls , <type 'str'> 125\n",
      "ward , 0.0% nulls , <type 'str'> 2092\n",
      "population , 0.0% nulls , <type 'numpy.int64'> 1049\n",
      "public_meeting , 5.6% nulls , <type 'bool'> 2\n",
      "recorded_by , 0.0% nulls , <type 'str'> 1\n",
      "scheme_management , 6.5% nulls , <type 'str'> 12\n",
      "scheme_name , 47.4% nulls , <type 'str'> 2696\n",
      "permit , 5.1% nulls , <type 'bool'> 2\n",
      "construction_year , 0.0% nulls , <type 'numpy.int64'> 55\n",
      "extraction_type , 0.0% nulls , <type 'str'> 18\n",
      "extraction_type_group , 0.0% nulls , <type 'str'> 13\n",
      "extraction_type_class , 0.0% nulls , <type 'str'> 7\n",
      "management , 0.0% nulls , <type 'str'> 12\n",
      "management_group , 0.0% nulls , <type 'str'> 5\n",
      "payment , 0.0% nulls , <type 'str'> 7\n",
      "payment_type , 0.0% nulls , <type 'str'> 7\n",
      "water_quality , 0.0% nulls , <type 'str'> 8\n",
      "quality_group , 0.0% nulls , <type 'str'> 6\n",
      "quantity , 0.0% nulls , <type 'str'> 5\n",
      "quantity_group , 0.0% nulls , <type 'str'> 5\n",
      "source , 0.0% nulls , <type 'str'> 10\n",
      "source_type , 0.0% nulls , <type 'str'> 7\n",
      "source_class , 0.0% nulls , <type 'str'> 3\n",
      "waterpoint_type , 0.0% nulls , <type 'str'> 7\n",
      "waterpoint_type_group , 0.0% nulls , <type 'str'> 6\n"
     ]
    }
   ],
   "source": [
    "for i in X_train.columns:\n",
    "    print i,',' ,'{:.1%}'.format(np.mean(X_train[i].isnull())),'nulls',',',type(X_train[i][0]), X_train[i].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>5.940000e+04</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37115.131768</td>\n",
       "      <td>317.650385</td>\n",
       "      <td>668.297239</td>\n",
       "      <td>34.077427</td>\n",
       "      <td>-5.706033e+00</td>\n",
       "      <td>0.474141</td>\n",
       "      <td>15.297003</td>\n",
       "      <td>5.629747</td>\n",
       "      <td>179.909983</td>\n",
       "      <td>1300.652475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21453.128371</td>\n",
       "      <td>2997.574558</td>\n",
       "      <td>693.116350</td>\n",
       "      <td>6.567432</td>\n",
       "      <td>2.946019e+00</td>\n",
       "      <td>12.236230</td>\n",
       "      <td>17.587406</td>\n",
       "      <td>9.633649</td>\n",
       "      <td>471.482176</td>\n",
       "      <td>951.620547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.164944e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18519.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.090347</td>\n",
       "      <td>-8.540621e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37061.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>34.908743</td>\n",
       "      <td>-5.021597e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55656.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1319.250000</td>\n",
       "      <td>37.178387</td>\n",
       "      <td>-3.326156e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74247.000000</td>\n",
       "      <td>350000.000000</td>\n",
       "      <td>2770.000000</td>\n",
       "      <td>40.345193</td>\n",
       "      <td>-2.000000e-08</td>\n",
       "      <td>1776.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     amount_tsh    gps_height     longitude      latitude  \\\n",
       "count  59400.000000   59400.000000  59400.000000  59400.000000  5.940000e+04   \n",
       "mean   37115.131768     317.650385    668.297239     34.077427 -5.706033e+00   \n",
       "std    21453.128371    2997.574558    693.116350      6.567432  2.946019e+00   \n",
       "min        0.000000       0.000000    -90.000000      0.000000 -1.164944e+01   \n",
       "25%    18519.750000       0.000000      0.000000     33.090347 -8.540621e+00   \n",
       "50%    37061.500000       0.000000    369.000000     34.908743 -5.021597e+00   \n",
       "75%    55656.500000      20.000000   1319.250000     37.178387 -3.326156e+00   \n",
       "max    74247.000000  350000.000000   2770.000000     40.345193 -2.000000e-08   \n",
       "\n",
       "        num_private   region_code  district_code    population  \\\n",
       "count  59400.000000  59400.000000   59400.000000  59400.000000   \n",
       "mean       0.474141     15.297003       5.629747    179.909983   \n",
       "std       12.236230     17.587406       9.633649    471.482176   \n",
       "min        0.000000      1.000000       0.000000      0.000000   \n",
       "25%        0.000000      5.000000       2.000000      0.000000   \n",
       "50%        0.000000     12.000000       3.000000     25.000000   \n",
       "75%        0.000000     17.000000       5.000000    215.000000   \n",
       "max     1776.000000     99.000000      80.000000  30500.000000   \n",
       "\n",
       "       construction_year  \n",
       "count       59400.000000  \n",
       "mean         1300.652475  \n",
       "std           951.620547  \n",
       "min             0.000000  \n",
       "25%             0.000000  \n",
       "50%          1986.000000  \n",
       "75%          2004.000000  \n",
       "max          2013.000000  "
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removal():\n",
    "    # id: we drop the id column because it is not a useful predictor.\n",
    "    # 'amount_tsh' is mostly blank - delete\n",
    "    # construction_year: we will NOT YET delete this column since ~35% of the values are zeros.\n",
    "    # wpt_name: not useful, delete (too many values)\n",
    "    # subvillage: too many values, delete\n",
    "    # scheme_name: this is almost 50% nulls, so we will delete this column\n",
    "    # num_private: we will delete this column because ~99% of the values are zeros.\n",
    "    # region: drop this b/c is seems very similar to region_code, though not 100% sure about this one!\n",
    "    z = ['id', 'amount_tsh', 'num_private', 'wpt_name', \n",
    "          'subvillage', 'scheme_name', 'region', 'extraction_type_group',\n",
    "         'payment', 'quality_group', 'quantity_group', 'source_type', 'waterpoint_type_group', 'ward']\n",
    "    for i in z:\n",
    "        del X_train[i]\n",
    "        del X_test[i]\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construction year: let's try filling in the nulls with a given value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construction():\n",
    "    for i in [X_train, X_test]:\n",
    "        i['construction_year'].replace(0, X_train['construction_year'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_recorded: this might be a useful variable for this analysis, although the year itself would be useless in a practical scenario moving into the future. We will convert this column into a datetime, and we will also create 'year_recorded' and 'month_recorded' columns just in case those levels prove to be useful. A visual inspection of both casts significant doubt on that possibility, but we'll proceed for now. We will delete date_recorded itself, since random forest cannot accept datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dates():\n",
    "    for i in [X_train, X_test]:\n",
    "        i['date_recorded'] = pd.to_datetime(i['date_recorded'])\n",
    "        i['date_recorded'] = pd.to_datetime(i['date_recorded'])\n",
    "        i['year_recorded'] = i['date_recorded'].apply(lambda x: x.year)\n",
    "        i['month_recorded'] = i['date_recorded'].apply(lambda x: x.month)\n",
    "        del i['date_recorded']\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gps_height`, `latitude`, `longitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def locs():\n",
    "    trans = ['longitude', 'latitude', 'gps_height', 'population']\n",
    "    for i in [X_train, X_test]:\n",
    "        i.loc[i.longitude == 0, 'latitude'] = 0\n",
    "        for z in trans:\n",
    "            i[z].replace(0., np.NaN, inplace = True)\n",
    "            i[z].replace(1., np.NaN, inplace = True)\n",
    "            data = X_train.groupby(['subvillage'])[z]\n",
    "            i[z] = data.transform(lambda x: x.fillna(x.mean()))\n",
    "            data = X_train.groupby(['district_code'])[z]\n",
    "            i[z] = data.transform(lambda x: x.fillna(x.mean()))\n",
    "            data = X_train.groupby(['basin'])[z]\n",
    "            i[z] = data.transform(lambda x: x.fillna(x.mean()))\n",
    "            i[z] = i[z].fillna(X_train[z].mean())\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# public_meeting: we will fill the nulls as 'False'\n",
    "# permit: we will fill the nulls as 'False'\n",
    "\n",
    "def bools():\n",
    "    z = ['public_meeting', 'permit']\n",
    "    for i in z:\n",
    "        X_train[i].fillna(False, inplace = True)\n",
    "        X_train[i] = X_train[i].apply(lambda x: float(x))\n",
    "        X_test[i].fillna(False, inplace = True)\n",
    "        X_test[i] = X_test[i].apply(lambda x: float(x))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "string columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def codes():\n",
    "    # convert region_code and district_code to string objects, since they are actually categorical variables\n",
    "    for i in ['region_code', 'district_code']:\n",
    "        X_train[i] = X_train[i].apply(lambda x: str(x))\n",
    "        X_test[i] = X_test[i].apply(lambda x: str(x))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dummies():\n",
    "    global X_train, X_test\n",
    "    columns = [i for i in X_train.columns if type(X_train[i].iloc[1]) == str]\n",
    "    for column in columns:\n",
    "        good_cols = []\n",
    "        X_train[column].fillna('NULL', inplace = True)\n",
    "        dumms = pd.get_dummies(X_train[column], prefix = column+'_')\n",
    "        for i in dumms.columns:\n",
    "        #    if chi2_contingency(pd.crosstab(dumms[i], y_train['status_group']))[1] < .001:\n",
    "            good_cols.append(i)\n",
    "        good_cols = [i for i in good_cols if i in pd.get_dummies(X_test[column], prefix = column+'_').columns]\n",
    "        X_train = pd.concat((X_train, pd.get_dummies(X_train[column], prefix = column+'_')[good_cols]), axis = 1)\n",
    "        X_test = pd.concat((X_test, pd.get_dummies(X_test[column], prefix = column+'_')[good_cols]), axis = 1)\n",
    "        del X_train[column]\n",
    "        del X_test[column]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummies3():\n",
    "    global X_train, X_test\n",
    "    columns = [i for i in X_train.columns if type(X_train[i].iloc[1]) == str]\n",
    "    status = pd.get_dummies(y_train['status_group'])\n",
    "    for column in columns:\n",
    "        good_cols = []\n",
    "        X_train[column].fillna('NULL', inplace = True)\n",
    "        dumms = pd.get_dummies(X_train[column], prefix = column+'_')\n",
    "        for i in dumms.columns:\n",
    "            if status[dumms[i] == 1]['functional'].mean() > (status['functional'].mean() + .1):\n",
    "                good_cols.append(i)\n",
    "            elif status[dumms[i] == 1]['non functional'].mean() > (status['non functional'].mean() + .1):\n",
    "                good_cols.append(i)\n",
    "            elif status[dumms[i] == 1]['functional needs repair'].mean() > (status['functional needs repair'].mean() + .1):\n",
    "                good_cols.append(i)\n",
    "        good_cols = [i for i in good_cols if i in pd.get_dummies(X_test[column], prefix = column+'_').columns]\n",
    "        X_train = pd.concat((X_train, pd.get_dummies(X_train[column], prefix = column+'_')[good_cols]), axis = 1)\n",
    "        X_test = pd.concat((X_test, pd.get_dummies(X_test[column], prefix = column+'_')[good_cols]), axis = 1)\n",
    "        del X_train[column]\n",
    "        del X_test[column]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dummies2():\n",
    "    global X_train, X_test\n",
    "    columns = [i for i in X_train.columns if type(X_train[i].iloc[1]) == str]\n",
    "    status = pd.get_dummies(y_train['status_group'])\n",
    "    for column in columns:\n",
    "        func = []\n",
    "        non_func = []\n",
    "        repair = []\n",
    "        X_train[column].fillna('NULL', inplace = True)\n",
    "        dumms = pd.get_dummies(X_train[column], prefix = column+'_')\n",
    "        for i in dumms.columns:\n",
    "            if status[dumms[i] == 1]['functional'].mean() > (status['functional'].mean() + .1):\n",
    "                func.append(i)\n",
    "            elif status[dumms[i] == 1]['non functional'].mean() > (status['non functional'].mean() + .1):\n",
    "                non_func.append(i)\n",
    "            elif status[dumms[i] == 1]['functional needs repair'].mean() > (status['functional needs repair'].mean() + .1):\n",
    "                repair.append(i)\n",
    "        func = [i for i in func if i in pd.get_dummies(X_test[column], prefix = column+'_').columns]\n",
    "        non_func = [i for i in non_func if i in pd.get_dummies(X_test[column], prefix = column+'_').columns]\n",
    "        repair = [i for i in repair if i in pd.get_dummies(X_test[column], prefix = column+'_').columns]\n",
    "        \n",
    "        for i in [X_train, X_test]:\n",
    "            if len(func) > 0:\n",
    "                i['func_'+column] = pd.get_dummies(i[column], prefix = column+'_')[func].max(axis=1)\n",
    "            if len(non_func) > 0:    \n",
    "                i['non_func_'+column] = pd.get_dummies(i[column], prefix = column+'_')[non_func].max(axis=1)\n",
    "            if len(repair) > 0:\n",
    "                i['repair_'+column] = pd.get_dummies(i[column], prefix = column+'_')[repair].max(axis=1)\n",
    "        del X_train[column]\n",
    "        del X_test[column]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "construction()\n",
    "locs()\n",
    "dates()\n",
    "bools()\n",
    "codes()\n",
    "removal()\n",
    "dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 1845)\n",
      "(14850, 1845)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(X_train)\n",
    "print np.shape(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(criterion='entropy',\n",
    "                                n_estimators=1000,\n",
    "                                max_features='auto',\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "                            \n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print \"%.4f\" % rf.oob_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80099326599326603"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rf, X_train, y_train.values.ravel())\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "pred = pd.DataFrame(predictions, columns = [y_test.columns[1]])\n",
    "del y_test['status_group']\n",
    "y_test = pd.concat((y_test, pred), axis = 1)\n",
    "y_test.to_csv('y_test.csv', sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', \n",
    "                              max_depth=1,\n",
    "                              random_state=0)\n",
    "\n",
    "ada = AdaBoostClassifier(base_estimator=tree,\n",
    "                         n_estimators=100, \n",
    "                         learning_rate=.5,\n",
    "                         random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(ada, X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73193602693602688"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy: 0.747 +/- 0.004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_range = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "param_grid = [{'C': param_range}]\n",
    "\n",
    "gs = GridSearchCV(estimator=LogisticRegression(random_state=0),\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=2,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "scores = cross_val_score(gs, X_train, y_train.values.ravel(), scoring='accuracy', cv=5)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_range = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "param_grid = [{'C': param_range, \n",
    "               'kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=SVC(),\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=2,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "scores = cross_val_score(gs, X_train, y_train.values.ravel(), scoring='accuracy', cv=5)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nonbi = []\n",
    "for i in X_train.columns:\n",
    "    if X_train[i].nunique() > 2:\n",
    "        nonbi.append(i)\n",
    "\n",
    "for i in nonbi:\n",
    "    del X_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70023569023569021"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "nb = BernoulliNB()\n",
    "\n",
    "scores = cross_val_score(nb, X_train, y_train.values.ravel())\n",
    "scores.mean()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
